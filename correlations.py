"""
Calculate ranked correlation between metrics and forward returns by period
For each period, calculate correlation across all stocks using RANKINGS (not absolute values)
- Both metrics and forward returns are ranked from 1 to n
- Correlation is calculated on the ranks, not the original values
- This is equivalent to Spearman rank correlation
Reads data from metrics.json (generated by get_metrics.py)
"""
import json
import numpy as np
from scipy.stats import pearsonr, spearmanr, rankdata
from typing import List, Tuple, Dict, Optional
import argparse
import re

# ============================================================================
# CONSTANTS
# ============================================================================

# Forward return periods to analyze
FORWARD_RETURN_PERIODS = ['total', '1y', '3y', '5y', '10y']

# Keys to exclude when detecting metrics (return metrics are used to evaluate predictive power, not metrics themselves)
EXCLUDED_KEYS = {
    'period', 'price', 'dividends', 'total_return', 'forward_return',
    'forward_return_1y', 'forward_return_3y', 'forward_return_5y', 'forward_return_10y'
}

# Statistical significance threshold
SIGNIFICANCE_THRESHOLD = 0.05

# Metric display names
METRIC_DISPLAY_NAMES = {
    'roa': 'ROA (Return on Assets)',
    'ebit_ppe': 'EBIT/PPE (EBIT per Property, Plant & Equipment)',
    'ebit_ppe_ttm': 'EBIT/PPE TTM (Trailing Twelve Months)'
}


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def get_forward_return_key(forward_period: str) -> str:
    """
    Get the forward return key for a given forward period.
    
    Args:
        forward_period: Forward period identifier ('total', '1y', '3y', '5y', '10y')
    
    Returns:
        The key name for the forward return in the data structure
    """
    if forward_period == 'total':
        return "forward_return"
    else:
        return f"forward_return_{forward_period}"


def format_forward_period_display(forward_period: str) -> str:
    """
    Format forward period for display.
    
    Args:
        forward_period: Forward period identifier
    
    Returns:
        Formatted display string
    """
    if forward_period == 'total':
        return "Total forward return"
    else:
        return f"{forward_period} forward return"


# ============================================================================
# DATA MODEL
# ============================================================================

class MetricData:
    """
    Data model class to hold extracted metric and forward return data.
    Provides efficient access and filtering methods.
    """
    
    def __init__(self):
        """
        Initialize empty MetricData structure.
        Structure: {forward_period: {time_period: {metric_key: [(metric_value, forward_return), ...]}}}
        """
        self.data: Dict[str, Dict[str, Dict[str, List[Tuple[float, float]]]]] = {
            period: {} for period in FORWARD_RETURN_PERIODS
        }
        self.metric_keys: List[str] = []
    
    def add_data_point(self, forward_period: str, time_period: str, metric_key: str, 
                      metric_value: float, forward_return: float):
        """Add a single data point to the structure."""
        if time_period not in self.data[forward_period]:
            self.data[forward_period][time_period] = {}
        if metric_key not in self.data[forward_period][time_period]:
            self.data[forward_period][time_period][metric_key] = []
        self.data[forward_period][time_period][metric_key].append((metric_value, forward_return))
    
    def get_pairs(self, forward_period: str, metric_key: str, time_period: Optional[str] = None) -> List[Tuple[float, float]]:
        """
        Get all (metric_value, forward_return) pairs for a given forward period and metric.
        
        Args:
            forward_period: Forward return period
            metric_key: Metric key
            time_period: Optional time period filter (if None, returns all time periods)
        
        Returns:
            List of (metric_value, forward_return) tuples
        """
        pairs = []
        periods_to_check = [time_period] if time_period else self.data[forward_period].keys()
        
        for tp in periods_to_check:
            if tp in self.data[forward_period] and metric_key in self.data[forward_period][tp]:
                pairs.extend(self.data[forward_period][tp][metric_key])
        
        return pairs
    
    def get_time_periods(self, forward_period: str) -> List[str]:
        """Get all time periods for a given forward period."""
        return sorted([p for p in self.data[forward_period].keys() 
                      if isinstance(p, str) or (isinstance(p, (int, float)) and p != 0)])


# ============================================================================
# DATA LOADING AND EXTRACTION
# ============================================================================

def load_data(filename: str = "metrics.json") -> List[dict]:
    """
    Load stock data from JSON file (metrics.json)
    
    Args:
        filename: Path to JSON file (default: metrics.json)
        
    Returns:
        List of stock data dictionaries
    """
    try:
        with open(filename, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: {filename} not found")
        return []
    except json.JSONDecodeError:
        print(f"Error: Invalid JSON in {filename}")
        return []


def extract_unified_data(data: List[dict], metric_keys: Optional[List[str]] = None) -> MetricData:
    """
    Extract metrics and forward return data into a unified MetricData structure.
    This is called once and the result is reused across all analysis functions.
    
    Args:
        data: List of stock data dictionaries
        metric_keys: List of metric keys to extract (if None, auto-detect from data)
        
    Returns:
        MetricData object containing all extracted data
    """
    metric_data = MetricData()
    
    # Auto-detect metric keys if not provided
    if metric_keys is None:
        metric_keys = []
        for stock in data:
            for entry in stock.get("data", []):
                for key, value in entry.items():
                    if key not in EXCLUDED_KEYS and value is not None and isinstance(value, (int, float)):
                        if key not in metric_keys:
                            metric_keys.append(key)
                break  # Only need to check one entry
    
    metric_data.metric_keys = metric_keys
    
    # Extract data grouped by time period and forward return period
    for stock in data:
        for entry in stock.get("data", []):
            time_period = entry.get("period")
            
            # Skip invalid periods
            if time_period is None or time_period == 0:
                continue
            
            # For each forward return period
            for forward_period in FORWARD_RETURN_PERIODS:
                forward_return_key = get_forward_return_key(forward_period)
                forward_return_value = entry.get(forward_return_key)
                
                # For each metric
                for metric_key in metric_keys:
                    metric_value = entry.get(metric_key)
                    
                    # Add valid data points (both metric and forward return must be valid)
                    if (metric_value is not None and forward_return_value is not None and 
                        isinstance(metric_value, (int, float)) and isinstance(forward_return_value, (int, float))):
                        metric_data.add_data_point(
                            forward_period, 
                            str(time_period), 
                            metric_key, 
                            float(metric_value), 
                            float(forward_return_value)
                        )
    
    return metric_data


def detect_available_metrics(data: List[dict]) -> dict:
    """
    Detect which metrics are available in the data
    
    Args:
        data: List of stock data dictionaries
    
    Returns:
        Dictionary mapping metric keys to their display names and descriptions
    """
    available_metrics = {}
    
    # First, find all potential metric keys by scanning all entries
    all_metric_keys = set()
    for stock in data:
        for entry in stock.get("data", []):
            for key, value in entry.items():
                if key not in EXCLUDED_KEYS:
                    # Check if it's a numeric value (could be a metric)
                    if value is not None and isinstance(value, (int, float)):
                        all_metric_keys.add(key)
    
    # Now check which of these have display names, or create default names
    for metric_key in sorted(all_metric_keys):
        if metric_key in METRIC_DISPLAY_NAMES:
            # Use the predefined display name
            available_metrics[metric_key] = METRIC_DISPLAY_NAMES[metric_key]
        else:
            # Create a default display name from the key
            # Convert snake_case to Title Case
            display_name = metric_key.replace('_', ' ').title()
            available_metrics[metric_key] = display_name
    
    return available_metrics


# ============================================================================
# ANALYSIS FUNCTIONS
# ============================================================================

def calculate_correlations(metric_values: List[float], forward_return_values: List[float]) -> dict:
    """
    Calculate correlation statistics between ranked metric values and ranked forward returns
    
    This function uses RANKED correlations (not absolute values):
    - Both metrics and forward returns are ranked from 1 to n
    - Correlation is calculated on the ranks, not the original values
    - This is equivalent to Spearman rank correlation
    
    Args:
        metric_values: List of metric values (e.g., ROA or EBIT/PPE)
        forward_return_values: List of forward return values
        
    Returns:
        Dictionary with correlation statistics (using ranked correlations)
    """
    
    if len(metric_values) < 2:
        return {
            "n_pairs": len(metric_values),
            "ranked_correlation": None,
            "ranked_pvalue": None,
            "error": "Insufficient data points for correlation"
        }
    
    # Convert to numpy arrays
    metric_array = np.array(metric_values)
    forward_return_array = np.array(forward_return_values)
    
    # Rank the data before correlating
    # Rankdata assigns ranks from 1 to n (where n = number of data points)
    # Average ranks are used for tied values
    # This converts absolute values to rankings
    metric_ranks = rankdata(metric_array, method='average')
    forward_return_ranks = rankdata(forward_return_array, method='average')
    
    # Calculate correlation on RANKED data (not absolute values)
    # This measures how well the ranking of metrics predicts the ranking of returns
    ranked_corr, ranked_p = pearsonr(metric_ranks, forward_return_ranks)
    
    return {
        "n_pairs": len(metric_values),
        "ranked_correlation": float(ranked_corr),
        "ranked_pvalue": float(ranked_p)
    }


def calculate_bucket_difference(pairs: List[Tuple[float, float]]) -> Optional[float]:
    """
    Calculate the difference between top 50% and bottom 50% bucket median returns.
    This is a shared function used by both ranking and buckets mode.
    
    Args:
        pairs: List of (metric_value, forward_return) tuples
    
    Returns:
        Difference between top and bottom bucket medians, or None if insufficient data
    """
    if len(pairs) < 2:
        return None
    
    metric_values = np.array([p[0] for p in pairs])
    forward_returns = np.array([p[1] for p in pairs])
    
    # Calculate median to split into top 50% and bottom 50%
    median_metric = np.median(metric_values)
    
    # Create masks for top and bottom 50%
    bottom_mask = metric_values <= median_metric
    top_mask = metric_values > median_metric
    
    bottom_returns = forward_returns[bottom_mask]
    top_returns = forward_returns[top_mask]
    
    if len(bottom_returns) > 0 and len(top_returns) > 0:
        bottom_median = np.median(bottom_returns)
        top_median = np.median(top_returns)
        return top_median - bottom_median
    
    return None


# ============================================================================
# RANKING FUNCTIONS
# ============================================================================

def rank_metrics_by_correlation(metric_data: MetricData, available_metrics: dict) -> List[Tuple[str, float]]:
    """
    Rank all metrics by their correlation with total forward return
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
    
    Returns:
        List of tuples (metric_key, correlation) sorted by correlation (descending)
    """
    forward_period = 'total'
    rankings = []
    
    for metric_key in available_metrics.keys():
        # Calculate correlations for each time period
        period_correlations = []
        period_weights = []
        
        time_periods = metric_data.get_time_periods(forward_period)
        
        for time_period in time_periods:
            pairs = metric_data.get_pairs(forward_period, metric_key, time_period)
            
            if len(pairs) >= 2:
                metric_values = [p[0] for p in pairs]
                forward_return_values = [p[1] for p in pairs]
                
                period_stat = calculate_correlations(metric_values, forward_return_values)
                ranked_corr = period_stat.get('ranked_correlation')
                
                if ranked_corr is not None:
                    period_correlations.append(ranked_corr)
                    period_weights.append(period_stat.get('n_pairs', 0))
        
        # Calculate weighted average correlation
        if period_correlations and period_weights:
            correlations_array = np.array(period_correlations)
            weights_array = np.array(period_weights)
            weighted_avg_correlation = np.average(correlations_array, weights=weights_array)
            rankings.append((metric_key, weighted_avg_correlation))
        else:
            rankings.append((metric_key, None))
    
    # Sort by correlation (descending), handling None values
    rankings.sort(key=lambda x: x[1] if x[1] is not None else float('-inf'), reverse=True)
    return rankings


def rank_metrics_by_bucket_difference(metric_data: MetricData, available_metrics: dict) -> List[Tuple[str, float]]:
    """
    Rank all metrics by the difference between top 50% and bottom 50% bucket returns
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
    
    Returns:
        List of tuples (metric_key, difference) sorted by difference (descending)
    """
    forward_period = 'total'
    rankings = []
    
    for metric_key in available_metrics.keys():
        pairs = metric_data.get_pairs(forward_period, metric_key)
        difference = calculate_bucket_difference(pairs)
        rankings.append((metric_key, difference))
    
    # Sort by difference (descending), handling None values
    rankings.sort(key=lambda x: x[1] if x[1] is not None else float('-inf'), reverse=True)
    return rankings


# ============================================================================
# DISPLAY FUNCTIONS
# ============================================================================

def display_rankings_by_correlation(rankings: List[Tuple[str, float]], available_metrics: dict):
    """Display metric rankings by correlation."""
    print("\n" + "="*100)
    print("Metric Rankings by Correlation (Total Forward Return)")
    print("="*100)
    print(f"\n{'Rank':<10} {'Metric':<50} {'Correlation':<20}")
    print("-"*100)
    for rank, (metric_key, score) in enumerate(rankings, start=1):
        metric_name = available_metrics.get(metric_key, metric_key)
        if score is not None:
            print(f"{rank:<10} {metric_name:<50} {score:<20.4f}")
        else:
            print(f"{rank:<10} {metric_name:<50} {'N/A':<20}")
    print("="*100)


def display_rankings_by_bucket_difference(rankings: List[Tuple[str, float]], available_metrics: dict):
    """Display metric rankings by bucket difference."""
    print("\n" + "="*100)
    print("Metric Rankings by Bucket Difference (Total Forward Return)")
    print("="*100)
    print(f"\n{'Rank':<10} {'Metric':<50} {'Top-Bottom Difference (%)':<30}")
    print("-"*100)
    for rank, (metric_key, score) in enumerate(rankings, start=1):
        metric_name = available_metrics.get(metric_key, metric_key)
        if score is not None:
            print(f"{rank:<10} {metric_name:<50} {score:<30.2f}")
        else:
            print(f"{rank:<10} {metric_name:<50} {'N/A':<30}")
    print("="*100)


def print_correlations_by_forward_period(results: dict, metric_name: str):
    """
    Print ranked correlation for each forward return period (1y, 3y, 5y, 10y) for a given metric
    
    Note: Correlations are calculated on RANKED values (not absolute values)
    
    Args:
        results: Dictionary mapping forward_return_period -> correlation results dict
        metric_name: Display name of the metric
    """
    print("\n" + "="*100)
    print(f"{metric_name} vs Forward Return Ranked Correlation by Forward Return Period")
    print("(Weighted average of ranked correlations across all time periods)")
    print("Note: Uses rankings of metrics and returns, not absolute values")
    print("="*100)
    print(f"\n{'Forward Period':<20} {'Ranked Corr':<15} {'p-value':<15} {'Significant':<15} {'N Pairs':<15} {'N Periods':<15}")
    print("-" * 100)
    
    for forward_period in FORWARD_RETURN_PERIODS:
        if forward_period in results:
            result = results[forward_period]
            ranked_corr = result.get('ranked_correlation')
            p_value = result.get('ranked_pvalue')
            n_pairs = result.get('n_pairs', 0)
            n_periods = result.get('n_periods', 0)
            
            if ranked_corr is not None and p_value is not None:
                is_significant = p_value < SIGNIFICANCE_THRESHOLD
                significance = "Yes" if is_significant else "No"
                period_display = format_forward_period_display(forward_period)
                print(f"{period_display:<20} {ranked_corr:<15.4f} {p_value:<15.4e} {significance:<15} {n_pairs:<15} {n_periods:<15}")
            else:
                period_display = format_forward_period_display(forward_period)
                print(f"{period_display:<20} {'N/A':<15} {'N/A':<15} {'N/A':<15} {n_pairs:<15} {n_periods:<15}")
    
    print("="*100)


def print_forward_period_correlations_summary(results: dict, metric_name: str):
    """
    Print summary statistics for ranked correlation results across forward return periods for a given metric
    
    Note: Correlations are calculated on RANKED values (not absolute values)
    
    Args:
        results: Dictionary mapping forward_return_period -> correlation results dict
        metric_name: Display name of the metric
    """
    if not results:
        return
    
    print("\n" + "="*100)
    print(f"{metric_name} vs Forward Return Ranked Correlation Summary")
    print("(Using rankings of metrics and returns, not absolute values)")
    print("="*100)
    
    significant_count = 0
    correlations = []
    weights = []  # Number of data points for each forward return period (for weighting)
    
    for forward_period in FORWARD_RETURN_PERIODS:
        if forward_period in results:
            result = results[forward_period]
            ranked_corr = result.get('ranked_correlation')
            p_value = result.get('ranked_pvalue')
            is_significant = p_value < SIGNIFICANCE_THRESHOLD if p_value is not None else False
            
            if is_significant:
                significant_count += 1
            if ranked_corr is not None:
                correlations.append(ranked_corr)
                weights.append(result.get('n_pairs', 0))  # Use number of data points as weight
    
    print("\nSummary Statistics Across Forward Return Periods (Ranked Correlations):")
    print(f"  Total forward return periods analyzed: {len([p for p in FORWARD_RETURN_PERIODS if p in results])}")
    print(f"  Periods with significant ranked correlation (p < {SIGNIFICANCE_THRESHOLD}): {significant_count}")
    if correlations:
        # Calculate weighted average correlation (weighted by number of data points)
        correlations_array = np.array(correlations)
        weights_array = np.array(weights)
        weighted_avg = np.average(correlations_array, weights=weights_array)
        
        print(f"  Average ranked correlation (unweighted): {np.mean(correlations):.4f}")
        print(f"  Weighted average ranked correlation (by data points): {weighted_avg:.4f}")
        print(f"  Median ranked correlation: {np.median(correlations):.4f}")
        print(f"  Min ranked correlation: {np.min(correlations):.4f}")
        print(f"  Max ranked correlation: {np.max(correlations):.4f}")
    print("="*100)


def print_period_correlations(period_stats: List[dict], metric_name: str):
    """
    Print ranked correlations for each individual time period (for total forward return only)
    
    Note: Correlations are calculated on RANKED values (not absolute values)
    
    Args:
        period_stats: List of correlation statistics dictionaries, each with 'time_period' key
        metric_name: Display name of the metric
    """
    if not period_stats:
        print("No period statistics available.")
        return
    
    print("\n" + "="*100)
    print(f"{metric_name} vs Total Forward Return Ranked Correlation by Time Period")
    print("(Using rankings of metrics and returns, not absolute values)")
    print("="*100)
    print(f"\n{'Time Period':<20} {'Ranked Corr':<15} {'p-value':<15} {'Significant':<15} {'N Pairs':<15}")
    print("-" * 100)
    
    # Sort by time period
    sorted_stats = sorted(period_stats, key=lambda x: x.get('time_period', 0))
    
    for stat in sorted_stats:
        time_period = stat.get('time_period', 'Unknown')
        ranked_corr = stat.get('ranked_correlation')
        p_value = stat.get('ranked_pvalue')
        n_pairs = stat.get('n_pairs', 0)
        
        if ranked_corr is not None and p_value is not None:
            is_significant = p_value < SIGNIFICANCE_THRESHOLD
            significance = "Yes" if is_significant else "No"
            print(f"{str(time_period):<20} {ranked_corr:<15.4f} {p_value:<15.4e} {significance:<15} {n_pairs:<15}")
        else:
            print(f"{str(time_period):<20} {'N/A':<15} {'N/A':<15} {'N/A':<15} {n_pairs:<15}")
    
    print("="*100)
    
    # Print summary statistics
    valid_correlations = [s.get('ranked_correlation') for s in sorted_stats 
                         if s.get('ranked_correlation') is not None]
    if valid_correlations:
        print(f"\nSummary Statistics Across Time Periods (Ranked Correlations):")
        print(f"  Total periods analyzed: {len(valid_correlations)}")
        significant_count = sum(1 for s in sorted_stats 
                               if s.get('ranked_pvalue') is not None and s.get('ranked_pvalue') < SIGNIFICANCE_THRESHOLD)
        print(f"  Periods with significant ranked correlation (p < {SIGNIFICANCE_THRESHOLD}): {significant_count}")
        print(f"  Average ranked correlation: {np.mean(valid_correlations):.4f}")
        print(f"  Median ranked correlation: {np.median(valid_correlations):.4f}")
        print(f"  Min ranked correlation: {np.min(valid_correlations):.4f}")
        print(f"  Max ranked correlation: {np.max(valid_correlations):.4f}")
        print("="*100)


# ============================================================================
# UI FUNCTIONS
# ============================================================================

def get_metric_combination_selection(available_metrics: dict) -> Optional[List[Tuple[str, int]]]:
    """
    Display metrics menu and get user's metric combination selection (e.g., "1+3" or "1-3")
    
    Args:
        available_metrics: Dictionary mapping metric keys to display names
    
    Returns:
        List of tuples (metric_key, sign) where sign is 1 for addition or -1 for subtraction,
        or None if user wants to exit
    """
    print("\n" + "="*80)
    print("Combine Metrics - Metric Selection")
    print("="*80)
    print("\nSelect which metrics to combine (e.g., type '1+3' to add, '1-3' to subtract):")
    print("  Use '+' to add metric ranks, '-' to subtract metric ranks")
    print("  Example: '1+3' adds ranks, '1-3' subtracts rank 3 from rank 1, '1+2-3' adds 1 and 2, then subtracts 3")
    
    metric_keys = sorted(available_metrics.keys())  # Sort for consistent ordering
    
    # Display metrics
    for i, metric_key in enumerate(metric_keys, start=1):
        print(f"  {i}. {available_metrics[metric_key]}")
    
    print("\n  'exit' - Exit")
    print("="*80)
    
    while True:
        try:
            choice = input("\nEnter metric numbers to combine (e.g., '1+3', '1-3', or '1+2-3'): ").strip().lower()
            
            if choice == 'exit':
                return None
            
            # Parse combination syntax (e.g., "1+3", "1-3", "1+2-3")
            # Split by + and - while preserving the operators
            # Match numbers with optional + or - prefix (first number may not have prefix)
            parts = re.findall(r'([+-]?)(\d+)', choice)
            
            if not parts:
                print("Invalid format. Please use format like '1+3', '1-3', or '1+2-3'.")
                continue
            
            selected_items = []
            for sign_str, num_str in parts:
                try:
                    idx = int(num_str)
                    if 1 <= idx <= len(metric_keys):
                        # Determine sign: + or no prefix = 1, - = -1
                        sign = -1 if sign_str == '-' else 1
                        selected_items.append((metric_keys[idx - 1], sign))
                    else:
                        print(f"Invalid metric number: {idx}. Please enter numbers between 1 and {len(metric_keys)}.")
                        break
                except ValueError:
                    print(f"Invalid number: {num_str}. Please enter valid metric numbers.")
                    break
            else:
                # All indices were valid
                if len(selected_items) > 0:
                    return selected_items
                else:
                    print("Please select at least one metric.")
        except KeyboardInterrupt:
            print("\n\nExiting...")
            return None
        except Exception as e:
            print(f"Error: {e}. Please try again.")


def get_metric_selection(available_metrics: dict, mode: str = None, 
                        metric_data: Optional[MetricData] = None) -> str:
    """
    Display a dynamic menu and get user's metric selection
    
    Args:
        available_metrics: Dictionary mapping metric keys to display names
        mode: Current analysis mode ('average', 'buckets', etc.)
        metric_data: MetricData object (needed for rank functionality)
    
    Returns:
        String indicating selected metric(s) or 'exit'
    """
    print("\n" + "="*80)
    print("Correlation Analysis - Metric Selection")
    print("="*80)
    print("\nSelect which metric to analyze:")
    
    # Build menu dynamically based on available metrics
    menu_items = []
    metric_keys = sorted(available_metrics.keys())  # Sort for consistent ordering
    
    # Add individual metrics
    for i, metric_key in enumerate(metric_keys, start=1):
        menu_items.append((str(i), metric_key, available_metrics[metric_key]))
        print(f"  {i}. {available_metrics[metric_key]}")
    
    # Add "All metrics" option if more than one metric
    if len(metric_keys) > 1:
        menu_items.append((str(len(metric_keys) + 1), 'all', 'All metrics'))
        print(f"  {len(metric_keys) + 1}. All metrics")
    
    # Add "Rank metrics" option for average and buckets modes
    rank_option_num = len(metric_keys) + (2 if len(metric_keys) > 1 else 1)
    if mode in ['average', 'buckets'] and metric_data is not None:
        menu_items.append((str(rank_option_num), 'rank', 'Rank metrics'))
        print(f"  {rank_option_num}. Rank metrics")
        exit_num = rank_option_num + 1
    else:
        exit_num = rank_option_num
    
    # Add exit option
    menu_items.append((str(exit_num), 'exit', 'Exit'))
    print(f"  {exit_num}. Exit")
    
    print("="*80)
    
    max_choice = exit_num
    while True:
        try:
            choice = input(f"\nEnter your choice (1-{max_choice}): ").strip()
            
            # Find the menu item for this choice
            for num, key, _ in menu_items:
                if choice == num:
                    if key == 'rank':
                        # Show rankings using separate display functions
                        if mode == 'average':
                            rankings = rank_metrics_by_correlation(metric_data, available_metrics)
                            display_rankings_by_correlation(rankings, available_metrics)
                        elif mode == 'buckets':
                            rankings = rank_metrics_by_bucket_difference(metric_data, available_metrics)
                            display_rankings_by_bucket_difference(rankings, available_metrics)
                        
                        # After showing rankings, ask user to select a metric
                        print("\nSelect a metric from the rankings above:")
                        print("  Enter rank number (1, 2, 3, etc.) - Select that metric")
                        print("  'all' - Analyze all metrics")
                        print("  'exit' - Exit")
                        metric_choice = input("\nEnter rank number, 'all', or 'exit': ").strip().lower()
                        
                        if metric_choice == 'exit':
                            return 'exit'
                        elif metric_choice == 'all':
                            return 'all'
                        else:
                            # Try to find metric by rank number
                            try:
                                rank_idx = int(metric_choice) - 1
                                if 0 <= rank_idx < len(rankings):
                                    return rankings[rank_idx][0]
                                else:
                                    print(f"Invalid rank number. Please enter 1-{len(rankings)}, 'all', or 'exit'.")
                                    continue
                            except ValueError:
                                # Try to find by metric name or key
                                for metric_key, _ in rankings:
                                    if metric_choice == metric_key or metric_choice.lower() in available_metrics.get(metric_key, '').lower():
                                        return metric_key
                                print(f"Invalid selection. Please try again.")
                                continue
                    else:
                        return key
            
            print(f"Invalid choice. Please enter a number between 1 and {max_choice}.")
        except KeyboardInterrupt:
            print("\n\nExiting...")
            return 'exit'
        except Exception as e:
            print(f"Error: {e}. Please try again.")


def show_command_menu() -> str:
    """
    Display available commands menu and get user selection
    
    Returns:
        Selected command mode or 'exit'
    """
    print("\n" + "="*80)
    print("Correlation Analysis - Available Commands")
    print("="*80)
    print("\nAvailable commands:")
    print("  1. average      - Calculate weighted average correlation across all time periods")
    print("  2. by-period   - Show correlations for each individual time period")
    print("  3. buckets      - Show median return for top 50% and bottom 50% of metric values")
    print("  4. combine      - Combine multiple metrics by adding/subtracting their rankings")
    print("  5. exit         - Exit the program")
    print("="*80)
    
    while True:
        try:
            choice = input("\nEnter command (1-5) or command name: ").strip().lower()
            
            # Handle numeric choices
            if choice == '1' or choice == 'average':
                return 'average'
            
            elif choice == '2' or choice == 'by-period' or choice == 'byperiod':
                return 'by-period'
            
            elif choice == '3' or choice == 'buckets':
                return 'buckets'
            
            elif choice == '4' or choice == 'combine':
                return 'combine'
            
            elif choice == '5' or choice == 'exit':
                return 'exit'
            
            else:
                print(f"Invalid choice. Please enter 1-5, or a command name (average, by-period, buckets, combine, exit).")
        except KeyboardInterrupt:
            print("\n\nExiting...")
            return 'exit'
        except Exception as e:
            print(f"Error: {e}. Please try again.")


# ============================================================================
# MODE EXECUTION FUNCTIONS
# ============================================================================

def run_average_mode(metric_data: MetricData, available_metrics: dict, metric_keys_to_process: List[str]):
    """
    Run average correlation mode - calculates weighted average correlation across all time periods
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
        metric_keys_to_process: List of metric keys to analyze
    """
    print("\nCalculating correlations for each time period, then weighted average across periods...")
    all_results = {metric_key: {} for metric_key in metric_keys_to_process}
    
    for forward_period in FORWARD_RETURN_PERIODS:
        for metric_key in metric_keys_to_process:
            # Calculate correlations for each time period
            period_correlations = []
            period_weights = []  # Sample sizes for weighting
            period_stats = []  # Store full stats for each period
            
            # Get all time periods for this forward return period
            time_periods = metric_data.get_time_periods(forward_period)
            
            for time_period in time_periods:
                pairs = metric_data.get_pairs(forward_period, metric_key, time_period)
                
                if len(pairs) >= 2:
                    metric_values = [p[0] for p in pairs]
                    forward_return_values = [p[1] for p in pairs]
                    
                    period_stat = calculate_correlations(metric_values, forward_return_values)
                    ranked_corr = period_stat.get('ranked_correlation')
                    
                    if ranked_corr is not None:
                        period_correlations.append(ranked_corr)
                        period_weights.append(period_stat.get('n_pairs', 0))
                        period_stat['time_period'] = time_period
                        period_stats.append(period_stat)
            
            # Calculate weighted average correlation across all time periods
            if period_correlations and period_weights:
                correlations_array = np.array(period_correlations)
                weights_array = np.array(period_weights)
                weighted_avg_correlation = np.average(correlations_array, weights=weights_array)
                
                # Calculate weighted average p-value (using Fisher's z-transformation would be more accurate,
                # but for simplicity we'll use weighted average of p-values)
                period_pvalues = [s.get('ranked_pvalue') for s in period_stats if s.get('ranked_pvalue') is not None]
                if period_pvalues:
                    # Weight p-values by sample size (inverse weighting - larger samples get more weight)
                    pvalues_array = np.array(period_pvalues)
                    weighted_avg_pvalue = np.average(pvalues_array, weights=weights_array)
                else:
                    weighted_avg_pvalue = None
                
                # Total number of pairs across all periods
                total_pairs = sum(period_weights)
                
                # Create summary stats
                stats = {
                    'forward_period': forward_period,
                    'metric_key': metric_key,
                    'ranked_correlation': float(weighted_avg_correlation),
                    'ranked_pvalue': float(weighted_avg_pvalue) if weighted_avg_pvalue is not None else None,
                    'n_pairs': total_pairs,
                    'n_periods': len(period_correlations),
                    'period_correlations': period_correlations,  # Store for reference
                    'period_stats': period_stats  # Store full period stats
                }
                
                all_results[metric_key][forward_period] = stats
    
    # Display results for each selected metric
    for metric_key in metric_keys_to_process:
        results = all_results[metric_key]
        if results:
            metric_name = available_metrics.get(metric_key, metric_key)
            print_correlations_by_forward_period(results, metric_name)
    
    # Print summary statistics for each selected metric
    for metric_key in metric_keys_to_process:
        results = all_results[metric_key]
        if results:
            metric_name = available_metrics.get(metric_key, metric_key)
            print_forward_period_correlations_summary(results, metric_name)


def run_by_period_mode(metric_data: MetricData, available_metrics: dict, metric_keys_to_process: List[str]):
    """
    Run by-period correlation mode - shows correlations for each individual time period (total forward return only)
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
        metric_keys_to_process: List of metric keys to analyze
    """
    # Only analyze total forward return
    forward_period = 'total'
    
    print(f"\nCalculating correlations for each time period (total forward return only)...")
    
    for metric_key in metric_keys_to_process:
        period_stats = []
        
        # Get all time periods for total forward return
        time_periods = metric_data.get_time_periods(forward_period)
        
        for time_period in time_periods:
            pairs = metric_data.get_pairs(forward_period, metric_key, time_period)
            
            if len(pairs) >= 2:
                metric_values = [p[0] for p in pairs]
                forward_return_values = [p[1] for p in pairs]
                
                period_stat = calculate_correlations(metric_values, forward_return_values)
                ranked_corr = period_stat.get('ranked_correlation')
                
                if ranked_corr is not None:
                    period_stat['time_period'] = time_period
                    period_stats.append(period_stat)
        
        # Display results for this metric
        if period_stats:
            metric_name = available_metrics.get(metric_key, metric_key)
            print_period_correlations(period_stats, metric_name)
        else:
            metric_name = available_metrics.get(metric_key, metric_key)
            print(f"\nNo valid correlation data found for {metric_name}.")


def run_buckets_mode(metric_data: MetricData, available_metrics: dict, metric_keys_to_process: List[str]):
    """
    Run buckets mode - shows median return for top 50% and bottom 50% of metric values
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
        metric_keys_to_process: List of metric keys to analyze
    """
    for metric_key in metric_keys_to_process:
        metric_name = available_metrics.get(metric_key, metric_key)
        
        # Print results for each forward return period
        print("\n" + "="*100)
        print(f"{metric_name} - Median Return by Metric Buckets")
        print("="*100)
        print(f"\n{'Forward Period':<20} {'Bottom 50% Median Return':<30} {'Top 50% Median Return':<30} {'Difference':<20} {'N Points':<15}")
        print("-"*100)
        
        for forward_period in FORWARD_RETURN_PERIODS:
            pairs = metric_data.get_pairs(forward_period, metric_key)
            
            if len(pairs) < 2:
                continue
            
            # Use shared bucket calculation function
            difference = calculate_bucket_difference(pairs)
            
            if difference is not None:
                # Calculate bucket medians for display
                metric_values = np.array([p[0] for p in pairs])
                forward_returns = np.array([p[1] for p in pairs])
                median_metric = np.median(metric_values)
                bottom_mask = metric_values <= median_metric
                top_mask = metric_values > median_metric
                bottom_returns = forward_returns[bottom_mask]
                top_returns = forward_returns[top_mask]
                
                bottom_median = np.median(bottom_returns)
                top_median = np.median(top_returns)
                
                period_display = format_forward_period_display(forward_period)
                print(f"{period_display:<20} {bottom_median:<30.2f}% {top_median:<30.2f}% {difference:<20.2f}% {len(pairs):<15,}")
        
        print("="*100)


def calculate_combined_scores(metric_data: MetricData, metric_items: List[Tuple[str, int]], 
                              forward_period: str) -> List[Tuple[float, float]]:
    """
    Calculate combined scores by adding/subtracting ranks of multiple metrics, then pair with forward returns.
    
    For each data point:
    1. Get metric values for all selected metrics
    2. Rank each metric within its time period
    3. Add/subtract the ranks according to the signs to get a combined score
    4. Pair this combined score with the forward return
    
    Matches data points by forward_return value (same stock/period) rather than by index,
    since different metrics may have different numbers of valid data points.
    
    Args:
        metric_data: MetricData object containing extracted data
        metric_items: List of tuples (metric_key, sign) where sign is 1 for addition or -1 for subtraction
        forward_period: Forward return period to use
    
    Returns:
        List of (combined_score, forward_return) tuples
    """
    combined_pairs = []
    
    # Extract metric keys (needed for matching)
    metric_keys = [item[0] for item in metric_items]
    
    # Get all time periods
    time_periods = metric_data.get_time_periods(forward_period)
    
    for time_period in time_periods:
        # Get pairs for all metrics for this time period
        all_metric_pairs = {}
        for metric_key in metric_keys:
            pairs = metric_data.get_pairs(forward_period, metric_key, time_period)
            if len(pairs) > 0:
                all_metric_pairs[metric_key] = pairs
        
        if not all_metric_pairs or len(all_metric_pairs) < len(metric_keys):
            continue
        
        # First, rank each metric within this time period
        metric_value_to_rank = {}  # For each metric, map (metric_value, forward_return) -> rank
        
        for metric_key in metric_keys:
            if metric_key in all_metric_pairs:
                pairs = all_metric_pairs[metric_key]
                metric_values = np.array([p[0] for p in pairs])
                ranks = rankdata(metric_values, method='average')
                
                # Create mapping from (metric_value, forward_return) to rank
                metric_value_to_rank[metric_key] = {}
                for i, (mv, fr) in enumerate(pairs):
                    # Use a tuple key that's tolerant of floating point differences
                    key = (round(mv, 10), round(fr, 10))
                    metric_value_to_rank[metric_key][key] = ranks[i]
        
        # Group pairs by forward_return value to match across metrics
        # Structure: forward_return -> {metric_key: metric_value}
        forward_return_groups = {}
        
        for metric_key in metric_keys:
            if metric_key in all_metric_pairs:
                for metric_value, forward_return in all_metric_pairs[metric_key]:
                    # Round to handle floating point precision issues
                    fr_rounded = round(forward_return, 10)
                    if fr_rounded not in forward_return_groups:
                        forward_return_groups[fr_rounded] = {}
                    forward_return_groups[fr_rounded][metric_key] = metric_value
        
        # For each forward return group, calculate combined score if all metrics are present
        for forward_return, metric_values_dict in forward_return_groups.items():
            # Check if all metrics are present
            if set(metric_values_dict.keys()) == set(metric_keys):
                # Get ranks for all metrics with their signs
                combined_score = 0.0
                all_ranks_found = True
                
                for metric_key, sign in metric_items:
                    metric_value = metric_values_dict[metric_key]
                    # Look up the rank using the (metric_value, forward_return) key
                    key = (round(metric_value, 10), forward_return)
                    if metric_key in metric_value_to_rank and key in metric_value_to_rank[metric_key]:
                        rank = metric_value_to_rank[metric_key][key]
                        combined_score += sign * rank  # Add or subtract based on sign
                    else:
                        # Rank not found - skip this group
                        all_ranks_found = False
                        break
                
                if all_ranks_found:
                    combined_pairs.append((combined_score, forward_return))
    
    return combined_pairs


def run_combine_mode(metric_data: MetricData, available_metrics: dict):
    """
    Run combine mode - combines multiple metrics by adding/subtracting their ranks, then shows buckets.
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
    """
    # Get metric combination selection
    selected_metric_items = get_metric_combination_selection(available_metrics)
    
    if selected_metric_items is None or len(selected_metric_items) == 0:
        print("No metrics selected. Exiting.")
        return
    
    # Create display name for combined metrics
    metric_parts = []
    for metric_key, sign in selected_metric_items:
        metric_name = available_metrics.get(metric_key, metric_key)
        if sign == 1:
            metric_parts.append(metric_name)
        else:
            metric_parts.append(f"- {metric_name}")
    combined_name = " + ".join(metric_parts)
    
    print(f"\nCombining metrics: {combined_name}")
    print("Calculating combined scores (add/subtract ranks)...")
    
    # Print results for each forward return period
    print("\n" + "="*100)
    print(f"Combined Metrics ({combined_name}) - Median Return by Combined Score Buckets")
    print("="*100)
    print(f"\n{'Forward Period':<20} {'Bottom 50% Median Return':<30} {'Top 50% Median Return':<30} {'Difference':<20} {'N Points':<15}")
    print("-"*100)
    
    for forward_period in FORWARD_RETURN_PERIODS:
        # Calculate combined scores
        combined_pairs = calculate_combined_scores(metric_data, selected_metric_items, forward_period)
        
        if len(combined_pairs) < 2:
            continue
        
        # Use shared bucket calculation function
        difference = calculate_bucket_difference(combined_pairs)
        
        if difference is not None:
            # Calculate bucket medians for display
            combined_scores = np.array([p[0] for p in combined_pairs])
            forward_returns = np.array([p[1] for p in combined_pairs])
            median_score = np.median(combined_scores)
            bottom_mask = combined_scores <= median_score
            top_mask = combined_scores > median_score
            bottom_returns = forward_returns[bottom_mask]
            top_returns = forward_returns[top_mask]
            
            bottom_median = np.median(bottom_returns)
            top_median = np.median(top_returns)
            
            period_display = format_forward_period_display(forward_period)
            print(f"{period_display:<20} {bottom_median:<30.2f}% {top_median:<30.2f}% {difference:<20.2f}% {len(combined_pairs):<15,}")
    
    print("="*100)


# ============================================================================
# MAIN FUNCTION
# ============================================================================

def main():
    """
    Main function to calculate and display correlation analysis by period
    Supports four modes:
    1. average - weighted average correlation across all time periods
    2. by-period - correlations for each individual time period (total forward return only)
    3. buckets - median return for top/bottom 50% buckets
    4. combine - combine multiple metrics by summing their ranks, then show buckets
    """
    parser = argparse.ArgumentParser(
        description='Calculate correlation between metrics and forward returns',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""Examples:
  python correlations.py                    # Interactive menu
  python correlations.py average            # Average correlation across all periods
  python correlations.py by-period          # Show correlations for each time period
  python correlations.py buckets            # Show median return for top/bottom 50% buckets
  python correlations.py combine            # Combine multiple metrics by summing ranks
        """
    )
    parser.add_argument(
        'mode',
        choices=['average', 'by-period', 'buckets', 'combine'],
        nargs='?',
        help='Analysis mode: "average" for weighted average across all periods, "by-period" for per-period correlations, "buckets" for median return by metric buckets, "combine" for combining multiple metrics'
    )
    
    args = parser.parse_args()
    
    # If no mode specified, show interactive menu
    if args.mode is None:
        selected_mode = show_command_menu()
        if selected_mode == 'exit':
            print("Exiting program.")
            return
        mode = selected_mode
    else:
        mode = args.mode
    
    # Load data first to detect available metrics
    print("\nLoading data from metrics.json...")
    data = load_data("metrics.json")
    
    if not data:
        print("No data loaded. Exiting.")
        return
    
    print(f"Loaded data for {len(data)} stock(s)")
    
    # Detect available metrics
    available_metrics = detect_available_metrics(data)
    
    if not available_metrics:
        print("No metrics found in data. Exiting.")
        return
    
    # Extract data once - this is now reused across all functions
    print("\nExtracting metrics and forward return data...")
    metric_data = extract_unified_data(data, list(available_metrics.keys()))
    
    # Run the appropriate mode
    if mode == 'combine':
        run_combine_mode(metric_data, available_metrics)
    else:
        # Get user's metric selection for other modes
        selected_metrics = get_metric_selection(available_metrics, mode, metric_data)
        
        if selected_metrics == 'exit':
            print("Exiting program.")
            return
        
        # Determine which metrics to process
        if selected_metrics == 'all':
            metric_keys_to_process = list(available_metrics.keys())
        else:
            metric_keys_to_process = [selected_metrics]
        
        # Run the appropriate mode
        if mode == 'average':
            run_average_mode(metric_data, available_metrics, metric_keys_to_process)
        elif mode == 'by-period':
            run_by_period_mode(metric_data, available_metrics, metric_keys_to_process)
        elif mode == 'buckets':
            run_buckets_mode(metric_data, available_metrics, metric_keys_to_process)


if __name__ == "__main__":
    main()
